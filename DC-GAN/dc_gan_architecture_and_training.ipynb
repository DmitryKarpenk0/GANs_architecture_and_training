{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2565c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:40:34.787650Z",
     "iopub.status.busy": "2024-04-29T11:40:34.787295Z",
     "iopub.status.idle": "2024-04-29T11:40:51.792358Z",
     "shell.execute_reply": "2024-04-29T11:40:51.791486Z"
    },
    "papermill": {
     "duration": 17.014717,
     "end_time": "2024-04-29T11:40:51.794776",
     "exception": false,
     "start_time": "2024-04-29T11:40:34.780059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install torchsummary\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532f6cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:40:51.807966Z",
     "iopub.status.busy": "2024-04-29T11:40:51.807592Z",
     "iopub.status.idle": "2024-04-29T11:40:54.478572Z",
     "shell.execute_reply": "2024-04-29T11:40:54.477821Z"
    },
    "papermill": {
     "duration": 2.680007,
     "end_time": "2024-04-29T11:40:54.480917",
     "exception": false,
     "start_time": "2024-04-29T11:40:51.800910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38d307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:40:54.494278Z",
     "iopub.status.busy": "2024-04-29T11:40:54.493486Z",
     "iopub.status.idle": "2024-04-29T11:40:54.547015Z",
     "shell.execute_reply": "2024-04-29T11:40:54.546273Z"
    },
    "papermill": {
     "duration": 0.061867,
     "end_time": "2024-04-29T11:40:54.548863",
     "exception": false,
     "start_time": "2024-04-29T11:40:54.486996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_size=256\n",
    "n_channels=1\n",
    "\n",
    "latent_size=100\n",
    "batch_size=64\n",
    "step_conv_channels=64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "lr=0.0002\n",
    "\n",
    "num_workers=4\n",
    "\n",
    "DATA_PATH = '...'\n",
    "EPOCH_START=0\n",
    "UPLOADED=False\n",
    "LOAD_FILENAME_PATH_GENERATOR=('weights/generator_epoch_%d.pth' % EPOCH_START)\n",
    "LOAD_FILENAME_PATH_DISCRIMINATOR=('weights/discriminator_epoch_%d.pth' % EPOCH_START)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0a943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:40:54.561336Z",
     "iopub.status.busy": "2024-04-29T11:40:54.561054Z",
     "iopub.status.idle": "2024-04-29T11:40:54.567435Z",
     "shell.execute_reply": "2024-04-29T11:40:54.566612Z"
    },
    "papermill": {
     "duration": 0.014783,
     "end_time": "2024-04-29T11:40:54.569309",
     "exception": false,
     "start_time": "2024-04-29T11:40:54.554526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312f582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:40:54.581704Z",
     "iopub.status.busy": "2024-04-29T11:40:54.581405Z",
     "iopub.status.idle": "2024-04-29T11:41:06.927705Z",
     "shell.execute_reply": "2024-04-29T11:41:06.926934Z"
    },
    "papermill": {
     "duration": 12.355131,
     "end_time": "2024-04-29T11:41:06.930150",
     "exception": false,
     "start_time": "2024-04-29T11:40:54.575019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Split(object):\n",
    "    def __call__(self, image):\n",
    "        return transforms.Grayscale(num_output_channels=n_channels)(image[1,:,:].view(n_channels,img_size,img_size))\n",
    "\n",
    "dataset = ImageFolder(DATA_PATH, transform=transforms.Compose([\n",
    "        transforms.Resize(img_size,interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        #transforms.RandomHorizontalFlip(p=0.5),\n",
    "        #transforms.Resize(upsample_transform, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        #transforms.RandomCrop((IMG_WIDTH,IMG_HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),\n",
    "        Split()\n",
    "        ]))\n",
    "dataloader = DataLoader(dataset, batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635fbea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:41:06.943592Z",
     "iopub.status.busy": "2024-04-29T11:41:06.943279Z",
     "iopub.status.idle": "2024-04-29T11:41:10.397616Z",
     "shell.execute_reply": "2024-04-29T11:41:10.396600Z"
    },
    "papermill": {
     "duration": 3.471184,
     "end_time": "2024-04-29T11:41:10.407411",
     "exception": false,
     "start_time": "2024-04-29T11:41:06.936227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch, _ = next(iter(dataloader))\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(make_grid(batch.to(device), padding=2, normalize=True).cpu() ,(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574066f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:41:10.441375Z",
     "iopub.status.busy": "2024-04-29T11:41:10.441072Z",
     "iopub.status.idle": "2024-04-29T11:41:10.454055Z",
     "shell.execute_reply": "2024-04-29T11:41:10.452555Z"
    },
    "papermill": {
     "duration": 0.032487,
     "end_time": "2024-04-29T11:41:10.456256",
     "exception": false,
     "start_time": "2024-04-29T11:41:10.423769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_size, step_conv_channels*16 * 4 * 4))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.Conv2d(step_conv_channels*16, step_conv_channels*16, 3, 1, 1),\n",
    "            nn.BatchNorm2d(step_conv_channels*16),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2), # 8x8 \n",
    "            nn.Conv2d(step_conv_channels*16, step_conv_channels*16, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(step_conv_channels*16),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2), # 16x16\n",
    "            nn.Conv2d(step_conv_channels*16, step_conv_channels*8, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(step_conv_channels*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2), # 32x32\n",
    "            nn.Conv2d(step_conv_channels*8, step_conv_channels*4, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(step_conv_channels*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2), # 64x64\n",
    "            nn.Conv2d(step_conv_channels*4, step_conv_channels*2, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(step_conv_channels*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2), # 128x128\n",
    "            nn.Conv2d(step_conv_channels*2, step_conv_channels, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(step_conv_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2), # 256x256\n",
    "            nn.Conv2d(step_conv_channels, n_channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        z = z.view(z.shape[0],-1)\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], step_conv_channels*16, 4, 4)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84ace9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:41:10.489055Z",
     "iopub.status.busy": "2024-04-29T11:41:10.488792Z",
     "iopub.status.idle": "2024-04-29T11:41:11.125233Z",
     "shell.execute_reply": "2024-04-29T11:41:11.124283Z"
    },
    "papermill": {
     "duration": 0.655211,
     "end_time": "2024-04-29T11:41:11.127256",
     "exception": false,
     "start_time": "2024-04-29T11:41:10.472045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = Generator()\n",
    "summary(g,(latent_size,1), device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a246c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:41:11.160969Z",
     "iopub.status.busy": "2024-04-29T11:41:11.160339Z",
     "iopub.status.idle": "2024-04-29T11:41:11.171537Z",
     "shell.execute_reply": "2024-04-29T11:41:11.170704Z"
    },
    "papermill": {
     "duration": 0.029897,
     "end_time": "2024-04-29T11:41:11.173434",
     "exception": false,
     "start_time": "2024-04-29T11:41:11.143537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, step_conv_channels, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AvgPool2d(2), #128x128\n",
    "            nn.Conv2d(step_conv_channels, step_conv_channels * 2, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AvgPool2d(2), #64x64\n",
    "            nn.BatchNorm2d(step_conv_channels * 2),\n",
    "            nn.Conv2d(step_conv_channels * 2, step_conv_channels * 4, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AvgPool2d(2), #32x32\n",
    "            nn.BatchNorm2d(step_conv_channels * 4),\n",
    "            nn.Conv2d(step_conv_channels * 4, step_conv_channels * 8, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AvgPool2d(2), #16x16\n",
    "            nn.BatchNorm2d(step_conv_channels * 8),\n",
    "            nn.Conv2d(step_conv_channels * 8, step_conv_channels * 16, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AvgPool2d(2), #8x8\n",
    "            nn.BatchNorm2d(step_conv_channels * 16),\n",
    "            nn.Conv2d(step_conv_channels * 16, step_conv_channels * 16, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AvgPool2d(2), #4x4\n",
    "            nn.BatchNorm2d(step_conv_channels * 16)\n",
    "        )\n",
    "        \n",
    "        self.adv_layer = nn.Sequential(nn.Linear(step_conv_channels * 16 * 4 * 4, 1), nn.Sigmoid())\n",
    "        \n",
    "        \n",
    "    def forward(self, img):\n",
    "        out = self.main(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.adv_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41708d88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:41:11.206495Z",
     "iopub.status.busy": "2024-04-29T11:41:11.206228Z",
     "iopub.status.idle": "2024-04-29T11:41:11.576728Z",
     "shell.execute_reply": "2024-04-29T11:41:11.575205Z"
    },
    "papermill": {
     "duration": 0.389843,
     "end_time": "2024-04-29T11:41:11.579152",
     "exception": false,
     "start_time": "2024-04-29T11:41:11.189309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d=Discriminator()\n",
    "summary(d,(1,img_size,img_size), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55563250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:41:11.613419Z",
     "iopub.status.busy": "2024-04-29T11:41:11.613126Z",
     "iopub.status.idle": "2024-04-29T11:41:11.635435Z",
     "shell.execute_reply": "2024-04-29T11:41:11.634605Z"
    },
    "papermill": {
     "duration": 0.041663,
     "end_time": "2024-04-29T11:41:11.637337",
     "exception": false,
     "start_time": "2024-04-29T11:41:11.595674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(model, criterion, epochs, lr, epochs_start=0, uploaded=False):\n",
    "    if epochs_start!=0 and not uploaded:\n",
    "        model['discriminator'].load_state_dict(torch.load(LOAD_FILENAME_PATH_DISCRIMINATOR))\n",
    "        model['generator'].load_state_dict(torch.load(LOAD_FILENAME_PATH_GENERATOR))\n",
    "        print('Model uploaded')\n",
    "        \n",
    "    model[\"discriminator\"].to(device)\n",
    "    model[\"generator\"].to(device)\n",
    "    model[\"discriminator\"].train()\n",
    "    model[\"generator\"].train()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    losses_g, losses_d, real_scores, fake_scores = [], [], [], []\n",
    "    \n",
    "    loss_g_per_batch, loss_d_per_batch, real_score_per_batch, fake_score_per_batch = [], [], [], []\n",
    "    \n",
    "    optimizer = {\n",
    "        \"discriminator\": torch.optim.Adam(model[\"discriminator\"].parameters(), \n",
    "                                          lr=lr, betas=(beta1, beta2)),\n",
    "        \"generator\": torch.optim.Adam(model[\"generator\"].parameters(),\n",
    "                                      lr=lr, betas=(beta1, beta2))\n",
    "    }\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        loss_d_per_epoch = []\n",
    "        loss_g_per_epoch = []\n",
    "        real_score_per_epoch = []\n",
    "        fake_score_per_epoch = []\n",
    "        for real_images, _ in dataloader:\n",
    "            # discriminator step\n",
    "            real_images = real_images.to(device)\n",
    "            optimizer[\"discriminator\"].zero_grad()\n",
    "\n",
    "            # real images to discriminator\n",
    "            real_preds = model[\"discriminator\"](real_images)\n",
    "            real_targets = torch.FloatTensor(real_images.size(0), 1,).uniform_(0.95, 1.0).to(device)\n",
    "            real_loss = criterion[\"discriminator\"](real_preds, real_targets)\n",
    "            \n",
    "            # generating images\n",
    "            latent = torch.randn(real_images.size(0), latent_size, device=device)\n",
    "            fake_images = model[\"generator\"](latent)\n",
    "\n",
    "            # generated images to discriminator\n",
    "            fake_targets = torch.FloatTensor(fake_images.size(0), 1,).uniform_(0.0, 0.05).to(device)\n",
    "            fake_preds = model[\"discriminator\"](fake_images)\n",
    "            fake_loss = criterion[\"discriminator\"](fake_preds, fake_targets)\n",
    "            \n",
    "            # logs\n",
    "            cur_real_score = torch.mean(real_preds).item()\n",
    "            cur_fake_score = torch.mean(fake_preds).item()\n",
    "            real_score_per_epoch.append(cur_real_score)\n",
    "            real_score_per_batch.append(cur_real_score)\n",
    "            fake_score_per_epoch.append(cur_fake_score)\n",
    "            fake_score_per_batch.append(cur_fake_score)\n",
    "            \n",
    "            # backward pass\n",
    "            loss_d = real_loss + fake_loss\n",
    "            loss_d.backward()\n",
    "            optimizer[\"discriminator\"].step()\n",
    "            \n",
    "            #logs\n",
    "            loss_d_per_epoch.append(loss_d.item())\n",
    "            loss_d_per_batch.append(loss_d.item())\n",
    "\n",
    "\n",
    "            # generator step\n",
    "            optimizer[\"generator\"].zero_grad()\n",
    "            \n",
    "            # generating images\n",
    "            latent = torch.randn(real_images.size(0), latent_size, device=device)\n",
    "            fake_images = model[\"generator\"](latent)\n",
    "            \n",
    "            # generated images to discriminator\n",
    "            preds = model[\"discriminator\"](fake_images)\n",
    "            targets = torch.FloatTensor(real_images.size(0), 1).uniform_(0.95, 1.0).to(device)\n",
    "            loss_g = criterion[\"generator\"](preds, targets)\n",
    "            \n",
    "            # backward pass\n",
    "            loss_g.backward()\n",
    "            optimizer[\"generator\"].step()\n",
    "            \n",
    "            #logs\n",
    "            loss_g_per_epoch.append(loss_g.item())\n",
    "            loss_g_per_batch.append(loss_g.item())\n",
    "            \n",
    "        # logs\n",
    "        losses_g.append(np.mean(loss_g_per_epoch))\n",
    "        losses_d.append(np.mean(loss_d_per_epoch))\n",
    "        real_scores.append(np.mean(real_score_per_epoch))\n",
    "        fake_scores.append(np.mean(fake_score_per_epoch))\n",
    "        \n",
    "        # logs\n",
    "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
    "            epoch+1+epochs_start, epochs+epochs_start, \n",
    "            losses_g[-1], losses_d[-1], real_scores[-1], fake_scores[-1]))\n",
    "\n",
    "        # examples\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Generated Images\")\n",
    "        plt.imshow(np.transpose(make_grid(fake_images.to(device)[:8], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "        plt.show()\n",
    "        \n",
    "        if (epoch+1+epochs_start)%10==0:\n",
    "            torch.save(model['generator'].state_dict(),'generator_epoch_%d.pth' % (epoch+1+epochs_start))\n",
    "            torch.save(model['discriminator'].state_dict(),'discriminator_epoch_%d.pth' % (epoch+1+epochs_start))\n",
    "            print('Model Saved! Epoch: %d' % (epoch+1+epochs_start))\n",
    "            \n",
    "    \n",
    "    return [losses_g, loss_g_per_batch, losses_d, loss_d_per_batch, real_scores, real_score_per_batch, fake_scores, fake_score_per_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a52c1cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:41:11.670397Z",
     "iopub.status.busy": "2024-04-29T11:41:11.670112Z",
     "iopub.status.idle": "2024-04-29T11:41:11.675616Z",
     "shell.execute_reply": "2024-04-29T11:41:11.674799Z"
    },
    "papermill": {
     "duration": 0.024207,
     "end_time": "2024-04-29T11:41:11.677521",
     "exception": false,
     "start_time": "2024-04-29T11:41:11.653314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8fd0ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:41:11.710335Z",
     "iopub.status.busy": "2024-04-29T11:41:11.710051Z",
     "iopub.status.idle": "2024-04-29T11:41:12.164892Z",
     "shell.execute_reply": "2024-04-29T11:41:12.164091Z"
    },
    "papermill": {
     "duration": 0.47378,
     "end_time": "2024-04-29T11:41:12.167188",
     "exception": false,
     "start_time": "2024-04-29T11:41:11.693408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Create the generator\n",
    "netG = Generator().to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.02.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "model = {\n",
    "    \"discriminator\": netD,\n",
    "    \"generator\": netG\n",
    "}\n",
    "\n",
    "criterion = {\n",
    "    \"discriminator\": nn.BCELoss(),\n",
    "    \"generator\": nn.BCELoss()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a993f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:41:12.203147Z",
     "iopub.status.busy": "2024-04-29T11:41:12.202817Z",
     "iopub.status.idle": "2024-04-29T11:41:12.206856Z",
     "shell.execute_reply": "2024-04-29T11:41:12.206011Z"
    },
    "papermill": {
     "duration": 0.024587,
     "end_time": "2024-04-29T11:41:12.208751",
     "exception": false,
     "start_time": "2024-04-29T11:41:12.184164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs=70\n",
    "lr=0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea27ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T11:41:12.242657Z",
     "iopub.status.busy": "2024-04-29T11:41:12.242351Z",
     "iopub.status.idle": "2024-04-29T22:21:04.891828Z",
     "shell.execute_reply": "2024-04-29T22:21:04.890649Z"
    },
    "papermill": {
     "duration": 38392.669557,
     "end_time": "2024-04-29T22:21:04.894376",
     "exception": false,
     "start_time": "2024-04-29T11:41:12.224819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logs = fit(model,criterion,epochs,lr, EPOCH_START, UPLOADED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e82e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T22:21:05.237979Z",
     "iopub.status.busy": "2024-04-29T22:21:05.237603Z",
     "iopub.status.idle": "2024-04-29T22:21:05.444677Z",
     "shell.execute_reply": "2024-04-29T22:21:05.443626Z"
    },
    "papermill": {
     "duration": 0.381286,
     "end_time": "2024-04-29T22:21:05.447186",
     "exception": false,
     "start_time": "2024-04-29T22:21:05.065900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "txts = ['losses_g.txt', 'loss_g_per_batch.txt', 'losses_d.txt', 'loss_d_per_batch.txt', \n",
    "                'real_scores.txt', 'real_score_per_batch.txt', 'fake_scores.txt', 'fake_score_per_batch.txt']\n",
    "\n",
    "for i in range(len(txts)):\n",
    "    with open(txts[i], 'w') as f:\n",
    "        for e in logs[i]:\n",
    "            f.write(str(e)+' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b6df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T22:21:05.770839Z",
     "iopub.status.busy": "2024-04-29T22:21:05.769760Z",
     "iopub.status.idle": "2024-04-29T22:21:07.256493Z",
     "shell.execute_reply": "2024-04-29T22:21:07.255492Z"
    },
    "papermill": {
     "duration": 1.656855,
     "end_time": "2024-04-29T22:21:07.266649",
     "exception": false,
     "start_time": "2024-04-29T22:21:05.609794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "    fake_images = model[\"generator\"](latent)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated Images\")\n",
    "plt.imshow(np.transpose(make_grid(fake_images.to(device), padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3937358,
     "sourceId": 6849438,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38438.065803,
   "end_time": "2024-04-29T22:21:10.114004",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-29T11:40:32.048201",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ac5c9a",
   "metadata": {
    "papermill": {
     "duration": 0.034365,
     "end_time": "2024-03-04T10:17:46.572777",
     "exception": false,
     "start_time": "2024-03-04T10:17:46.538412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ddp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ddp.py\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.utils.spectral_norm as spectral_norm\n",
    "import torch.nn.functional as F\n",
    "import functools\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "img_size = 256\n",
    "n_channels = 1\n",
    "\n",
    "latent_size = 128\n",
    "batch_size = 9\n",
    "\n",
    "is_parallel = True\n",
    "\n",
    "step_conv_channels=32\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "beta1 = 0.0 \n",
    "beta2 = 0.999\n",
    "\n",
    "gamma = 0.1 # discriminator reg constant\n",
    "gamma_decay = False\n",
    "\n",
    "lr={\n",
    "    'generator': 0.000025,\n",
    "    'discriminator': 0.000025\n",
    "}\n",
    "\n",
    "\n",
    "if is_parallel:\n",
    "    num_workers = 0\n",
    "    world_size = 2\n",
    "else:\n",
    "    num_workers = 4\n",
    "\n",
    "DATA_PATH = '...'\n",
    "EPOCH_START = 0\n",
    "LOAD_FILENAME_PATH_GENERATOR = ('weights/generator_epoch_%d.pth' % EPOCH_START)\n",
    "LOAD_FILENAME_PATH_DISCRIMINATOR = ('weights/discriminator_epoch_%d.pth' % EPOCH_START)\n",
    "\n",
    "#print('Lerning rate:', lr)\n",
    "#print('device:',device)\n",
    "#print('device count:', torch.cuda.device_count())\n",
    "\n",
    "class Split(object):\n",
    "    def __call__(self, image):\n",
    "        return transforms.Grayscale(num_output_channels=n_channels)(image[1,:,:].view(n_channels,img_size,img_size))\n",
    "\n",
    "dataset = ImageFolder(DATA_PATH, transform=transforms.Compose([\n",
    "        transforms.Resize(img_size,interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        #transforms.RandomHorizontalFlip(p=0.5),\n",
    "        #transforms.Resize(upsample_transform, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        #transforms.RandomCrop((IMG_WIDTH,IMG_HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),\n",
    "        Split()\n",
    "        ]))\n",
    "\n",
    "# for parallelism\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "def prepare_dataloader_for_paralellism(rank, world_size, batch_size, pin_memory = False, num_workers = 0):\n",
    "    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank, shuffle=True, drop_last=False)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, pin_memory=pin_memory, \n",
    "                            num_workers=num_workers, drop_last=False, shuffle=False, sampler=sampler)\n",
    "    return dataloader\n",
    "\n",
    "if not is_parallel:\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=True,num_workers=num_workers)\n",
    "\n",
    "    \n",
    "class Self_Attention(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "    def __init__(self,in_dim):\n",
    "        super(Self_Attention,self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "        \n",
    "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        self.softmax  = nn.Softmax(dim=-1) #\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            inputs :\n",
    "                x : input feature maps( B X C X W X H)\n",
    "            returns :\n",
    "                out : self attention value + input feature \n",
    "                attention: B X N X N (N is Width*Height)\n",
    "        \"\"\"\n",
    "        m_batchsize,C,width ,height = x.size()\n",
    "        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\n",
    "        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)\n",
    "        energy =  torch.bmm(proj_query,proj_key) # transpose check\n",
    "        attention = self.softmax(energy) # BX (N) X (N) \n",
    "        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N\n",
    "\n",
    "        out = torch.bmm(proj_value,attention.permute(0,2,1) )\n",
    "        out = out.view(m_batchsize,C,width,height)\n",
    "        \n",
    "        out = self.gamma*out + x\n",
    "        return out    \n",
    "    \n",
    "class GBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, upsample=None, channel_ratio=4):\n",
    "        super(GBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels, self.out_channels = in_channels, out_channels\n",
    "        hidden_channels = in_channels // channel_ratio\n",
    "        self.upsample = upsample\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        self.conv1 = spectral_norm(nn.Conv2d(in_channels, hidden_channels, kernel_size = 1, padding = 0))\n",
    "        self.conv2 = spectral_norm(nn.Conv2d(hidden_channels, hidden_channels, kernel_size = 3, padding = 1))\n",
    "        self.conv3 = spectral_norm(nn.Conv2d(hidden_channels, hidden_channels, kernel_size = 3, padding = 1))\n",
    "        self.conv4 = spectral_norm(nn.Conv2d(hidden_channels, out_channels, kernel_size = 1, padding = 0))\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.bn3 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.bn4 = nn.BatchNorm2d(hidden_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.conv1(self.activation(self.bn1(x)))\n",
    "        h = self.activation(self.bn2(h))\n",
    "        \n",
    "        if self.in_channels != self.out_channels:\n",
    "            x = x[:, :self.out_channels]\n",
    "        \n",
    "        if self.upsample:\n",
    "            h = self.upsample(h)\n",
    "            x = self.upsample(x)\n",
    "            \n",
    "        h = self.conv2(h)\n",
    "        h = self.conv3(self.activation(self.bn3(h)))\n",
    "        h = self.conv4(self.activation(self.bn4(h)))\n",
    "        \n",
    "        return x + h\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, encoding_dims = 128, step_channels = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.linear = spectral_norm(nn.Linear(encoding_dims, 4 * 4 * 16 * step_channels))\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            GBlock(16 * step_channels, 16 * step_channels, upsample = None),\n",
    "            GBlock(16 * step_channels, 16 * step_channels, upsample = functools.partial(F.interpolate, scale_factor=2)),\n",
    "            GBlock(16 * step_channels, 16 * step_channels, upsample = None),\n",
    "            GBlock(16 * step_channels, 8 * step_channels, upsample = functools.partial(F.interpolate, scale_factor=2)),\n",
    "            GBlock(8 * step_channels, 8 * step_channels, upsample = None),\n",
    "            GBlock(8 * step_channels, 8 * step_channels, upsample = functools.partial(F.interpolate, scale_factor=2)),\n",
    "            GBlock(8 * step_channels, 8 * step_channels, upsample = None),\n",
    "            GBlock(8 * step_channels, 4 * step_channels, upsample = functools.partial(F.interpolate, scale_factor=2)),\n",
    "            Self_Attention(4 * step_channels),\n",
    "            GBlock(4 * step_channels, 4 * step_channels, upsample = None),\n",
    "            GBlock(4 * step_channels, 2 * step_channels, upsample = functools.partial(F.interpolate, scale_factor=2)),\n",
    "            GBlock(2 * step_channels, 2 * step_channels, upsample = None),\n",
    "            GBlock(2 * step_channels, step_channels, upsample = functools.partial(F.interpolate, scale_factor=2))\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.BatchNorm2d(step_channels),\n",
    "            nn.ReLU(),\n",
    "            spectral_norm(nn.Conv2d(step_channels, 1, kernel_size = 3, padding = 1)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        z = z.view(z.size(0),-1)\n",
    "        h = self.linear(z)\n",
    "        h = h.view(h.size(0), -1, 4, 4)\n",
    "        h = self.blocks(h)\n",
    "        h = self.output_layer(h)\n",
    "        \n",
    "        return h\n",
    "    \n",
    "class DBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample = None, channel_ratio = 4):\n",
    "        super(DBlock, self).__init__()\n",
    "        \n",
    "        hidden_channels = out_channels // channel_ratio\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        self.conv1 = spectral_norm(nn.Conv2d(in_channels, hidden_channels, kernel_size = 1, padding = 0))\n",
    "        self.conv2 = spectral_norm(nn.Conv2d(hidden_channels, hidden_channels, kernel_size = 3, padding = 1))\n",
    "        self.conv3 = spectral_norm(nn.Conv2d(hidden_channels, hidden_channels, kernel_size = 3, padding = 1))\n",
    "        self.conv4 = spectral_norm(nn.Conv2d(hidden_channels, out_channels, kernel_size = 1, padding = 0))\n",
    "        \n",
    "        self.learnable_sc = True if (in_channels != out_channels) else False\n",
    "        if self.learnable_sc:\n",
    "            self.conv_sc = spectral_norm(nn.Conv2d(in_channels, out_channels - in_channels, kernel_size = 1, padding = 0))\n",
    "    \n",
    "    def shortcut(self, x):\n",
    "        if self.downsample:\n",
    "            x = self.downsample(x)\n",
    "        if self.learnable_sc:\n",
    "            x = torch.cat([x, self.conv_sc(x)], 1)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.conv1(self.activation(x))\n",
    "        h = self.conv2(self.activation(h))\n",
    "        h = self.conv3(self.activation(h))\n",
    "        h = self.activation(h)\n",
    "        \n",
    "        if self.downsample:\n",
    "            h = self.downsample(h)\n",
    "            \n",
    "        h = self.conv4(h)\n",
    "        \n",
    "        return h + self.shortcut(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, step_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.input_conv = spectral_norm(nn.Conv2d(1, step_channels, kernel_size=3, padding = 1))\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            DBlock(step_channels, 2 * step_channels, downsample = nn.AvgPool2d(2)),\n",
    "            DBlock(2 * step_channels, 2 * step_channels, downsample = None),\n",
    "            DBlock(2 * step_channels, 4 * step_channels, downsample = nn.AvgPool2d(2)),\n",
    "            DBlock(4 * step_channels, 4 * step_channels, downsample = None),\n",
    "            Self_Attention(4 * step_channels),\n",
    "            DBlock(4 * step_channels, 8 * step_channels, downsample = nn.AvgPool2d(2)),\n",
    "            DBlock(8 * step_channels, 8 * step_channels, downsample = None),\n",
    "            DBlock(8 * step_channels, 8 * step_channels, downsample = nn.AvgPool2d(2)),\n",
    "            DBlock(8 * step_channels, 8 * step_channels, downsample = None),\n",
    "            DBlock(8 * step_channels, 16 * step_channels, downsample = nn.AvgPool2d(2)),\n",
    "            DBlock(16 * step_channels, 16 * step_channels, downsample = None),\n",
    "            DBlock(16 * step_channels, 16 * step_channels, downsample = nn.AvgPool2d(2)),\n",
    "            DBlock(16 * step_channels, 16 * step_channels, downsample = None),\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Linear(16 * step_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.input_conv(x)\n",
    "        h = self.blocks(h)\n",
    "        h = torch.sum(self.activation(h), [2, 3])\n",
    "        h = self.linear(h)\n",
    "        \n",
    "        return h\n",
    "    \n",
    "def discriminator_regularizer(D1_logits, D1_input, D2_logits, D2_input):\n",
    "    D1 = torch.sigmoid(D1_logits)\n",
    "    D2 = torch.sigmoid(D2_logits)\n",
    "    grad_D1_logits = torch.autograd.grad(D1_logits, D1_input, torch.ones_like(D1_logits),\n",
    "                                         create_graph=True, retain_graph=True, only_inputs=True, allow_unused=True)[0]\n",
    "    grad_D2_logits = torch.autograd.grad(D2_logits, D2_input, torch.ones_like(D2_logits),\n",
    "                                        create_graph=True, retain_graph=True, only_inputs=True, allow_unused=True)[0]\n",
    "    norm_grad_D1_logits = torch.norm(grad_D1_logits.view(D1_input.shape[0], -1), dim = 1, keepdim = True)\n",
    "    norm_grad_D2_logits = torch.norm(grad_D2_logits.view(D2_input.shape[0], -1), dim = 1, keepdim = True)\n",
    "    \n",
    "    reg_D1 = (1.0-D1)**2 * norm_grad_D1_logits**2\n",
    "    reg_D2 = D2**2 * norm_grad_D2_logits**2\n",
    "    reg = torch.mean(reg_D1 + reg_D2)\n",
    "    \n",
    "    return reg\n",
    "\n",
    "def save_samples(samples, epoch):\n",
    "    print('Saving samples')\n",
    "    if not os.path.isdir('images'):\n",
    "        os.mkdir('images')\n",
    "    if not os.path.isdir('images/images_{}_epochs'.format(epoch)):\n",
    "        os.mkdir('images/images_{}_epochs'.format(epoch))\n",
    "    for i in range(samples.shape[0]):\n",
    "        save_image((samples[i]+1)/2. , 'images/images_{}_epochs/{}.png'.format(epoch, i))\n",
    "    print('Saving samples complete')\n",
    "\n",
    "def save_logs(logs, epoch=0):\n",
    "    txts=['losses_g','loss_g_per_batch', 'losses_d','loss_d_per_batch','real_scores','real_score_per_batch','fake_scores','fake_score_per_batch']\n",
    "    for i, txt in enumerate(txts):\n",
    "        with open('logs/'+txt+'_{}_epoch.txt'.format(epoch), 'w') as f:\n",
    "            for e in logs[i]:\n",
    "                f.write(str(e)+' ')\n",
    "    \n",
    "    print('Logs saved')\n",
    "\n",
    "def fit(rank, model, dataloader, criterion, epochs, lr, epochs_start=0, uploaded=False):\n",
    "    if epochs_start!=0 and not uploaded:\n",
    "        map_location = {'cuda:%d' % 0: 'cuda:%d' % rank}\n",
    "        model['discriminator'].load_state_dict(torch.load(LOAD_FILENAME_PATH_DISCRIMINATOR, map_location=map_location))\n",
    "        model['generator'].load_state_dict(torch.load(LOAD_FILENAME_PATH_GENERATOR, map_location=map_location))\n",
    "        print('Model uploaded')\n",
    "        \n",
    "    #model[\"discriminator\"].to(device)\n",
    "    #model[\"generator\"].to(device)\n",
    "    model[\"discriminator\"].train()\n",
    "    model[\"generator\"].train()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    losses_g = []\n",
    "    losses_d = []\n",
    "    real_scores = []\n",
    "    fake_scores = []\n",
    "    \n",
    "    loss_g_per_batch = []\n",
    "    loss_d_per_batch = []\n",
    "    real_score_per_batch = []\n",
    "    fake_score_per_batch = []\n",
    "    \n",
    "    optimizer = {\n",
    "        \"discriminator\": torch.optim.Adam(model[\"discriminator\"].parameters(), \n",
    "                                          lr=lr['discriminator'], betas=(beta1, beta2)),\n",
    "        \"generator\": torch.optim.Adam(model[\"generator\"].parameters(),\n",
    "                                      lr=lr['generator'], betas=(beta1, beta2))\n",
    "    }\n",
    "    \n",
    "    gamma_reg = gamma\n",
    "    \n",
    "    for epoch in tqdm(range(epochs_start, epochs)):\n",
    "        loss_d_per_epoch = []\n",
    "        loss_g_per_epoch = []\n",
    "        real_score_per_epoch = []\n",
    "        fake_score_per_epoch = []\n",
    "        \n",
    "        if gamma_decay:\n",
    "            gamma_reg = gamma_reg * 0.01**(epoch/epochs)\n",
    "        \n",
    "        if is_parallel:\n",
    "            dataloader.sampler.set_epoch(epoch)\n",
    "        \n",
    "        for real_images, _ in dataloader:#tqdm(dataloader):\n",
    "             \n",
    "            # discriminator step\n",
    "            real_images = real_images.to(rank).requires_grad_()\n",
    "            optimizer[\"discriminator\"].zero_grad()\n",
    "\n",
    "            # real images to discriminator\n",
    "            real_preds = model[\"discriminator\"](real_images)\n",
    "            \n",
    "            # generating images\n",
    "            latent = torch.randn(real_images.size(0), latent_size, 1, 1, device=device)\n",
    "            fake_images = model[\"generator\"](latent)\n",
    "\n",
    "            # generated images to discriminator\n",
    "            fake_preds = model[\"discriminator\"](fake_images)\n",
    "            \n",
    "            # logs\n",
    "            cur_fake_score = torch.mean(fake_preds).item()\n",
    "            cur_real_score = torch.mean(real_preds).item()\n",
    "            real_score_per_epoch.append(cur_real_score)\n",
    "            real_score_per_batch.append(cur_real_score)\n",
    "            fake_score_per_epoch.append(cur_fake_score)\n",
    "            fake_score_per_batch.append(cur_fake_score)\n",
    "            \n",
    "            # backward pass\n",
    "            loss_d = criterion['discriminator'](real_preds,fake_preds)\n",
    "            loss_d += gamma_reg / 2. * discriminator_regularizer(real_preds, real_images, fake_preds, fake_images)\n",
    "            loss_d.backward()\n",
    "            optimizer[\"discriminator\"].step()\n",
    "            \n",
    "            # logs\n",
    "            loss_d_per_epoch.append(loss_d.item())\n",
    "            loss_d_per_batch.append(loss_d.item())\n",
    "            \n",
    "            # generator step\n",
    "            optimizer[\"generator\"].zero_grad()\n",
    "            \n",
    "            # generating images\n",
    "            latent = torch.randn(real_images.size(0), latent_size, 1, 1, device=rank)\n",
    "            fake_images = model[\"generator\"](latent)\n",
    "            \n",
    "            # generated images to discriminator\n",
    "            preds = model[\"discriminator\"](fake_images)\n",
    "            loss_g = criterion[\"generator\"](preds)\n",
    "            \n",
    "            # backward pass\n",
    "            loss_g.backward()\n",
    "            optimizer[\"generator\"].step()\n",
    "            \n",
    "            # logs\n",
    "            loss_g_per_epoch.append(loss_g.item())\n",
    "            loss_g_per_batch.append(loss_g.item())\n",
    "            \n",
    "        # logs\n",
    "        losses_g.append(np.mean(loss_g_per_epoch))\n",
    "        losses_d.append(np.mean(loss_d_per_epoch))\n",
    "        real_scores.append(np.mean(real_score_per_epoch))\n",
    "        fake_scores.append(np.mean(fake_score_per_epoch))\n",
    "        \n",
    "        # logs\n",
    "        if rank==0:\n",
    "            print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
    "                epoch+1, epochs, \n",
    "                losses_g[-1], losses_d[-1], real_scores[-1], fake_scores[-1]))\n",
    "            losses = [losses_g, loss_g_per_batch, losses_d, loss_d_per_batch, real_scores, real_score_per_batch, fake_scores, fake_score_per_batch]\n",
    "            save_logs(losses, epoch = epoch + 1)\n",
    "            for l in losses:\n",
    "                l.clear()\n",
    "\n",
    "        # examples\n",
    "        if rank==0:\n",
    "            #plt.figure(figsize=(12,12))\n",
    "            #plt.axis(\"off\")\n",
    "            #plt.title(\"Generated Images\")\n",
    "            #plt.imshow(np.transpose(make_grid(fake_images.to(rank)[:8], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "            #plt.show()\n",
    "            save_samples(fake_images, epoch+1)\n",
    "        \n",
    "        if (epoch+1+epochs_start)%1==0 and rank==0:\n",
    "            torch.save(model['generator'].state_dict(),'weights/generator_epoch_%d.pth' % (epoch+1))\n",
    "            torch.save(model['discriminator'].state_dict(),'weights/discriminator_epoch_%d.pth' % (epoch+1))\n",
    "            print('Model Saved! Epoch: %d' % (epoch+1+epochs_start))\n",
    "            \n",
    "    \n",
    "    return [losses_g, loss_g_per_batch, losses_d, loss_d_per_batch, real_scores, real_score_per_batch, fake_scores, fake_score_per_batch]\n",
    "    \n",
    "def show_samples(model, amount=16):\n",
    "    model['generator'].eval()\n",
    "    with torch.no_grad():\n",
    "        z = np.array([np.random.normal(0, 1, latent_size) for i in range(amount)])\n",
    "        output = model['generator'](torch.FloatTensor(z).to(device))\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Generated Images\")\n",
    "    plt.imshow(np.transpose(make_grid(output.to(device), padding=2, normalize=True).cpu() ,(1,2,0)))\n",
    "    \n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    def _weights_init(module):\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d):\n",
    "            nn.init.normal_(module.weight, 0.0, 0.02)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            nn.init.normal_(module.weight, 1.0, 0.02)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    return m.apply(_weights_init)\n",
    "\n",
    "# hinge losses \n",
    "def generator_loss(out_fake):\n",
    "    return - out_fake.mean()\n",
    "    \n",
    "def discriminator_loss(out_real,out_fake):\n",
    "    return torch.nn.ReLU()(1.0 + out_fake).mean() + torch.nn.ReLU()(1.0 - out_real).mean()\n",
    "\n",
    "# Distributed Data Parallel Setup\n",
    "\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "def setup(rank, world_size):    \n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '5554'    \n",
    "    \n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    \n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "    \n",
    "def main(rank, world_size):\n",
    "    setup(rank, world_size)\n",
    "    if rank==0:\n",
    "        print('Setup done, starting preparing dataloader')\n",
    "    \n",
    "    dataloader = prepare_dataloader_for_paralellism(rank, world_size, batch_size)\n",
    "    if rank==0:\n",
    "        print('Dataloader prepared')\n",
    "    \n",
    "    generator = Generator(encoding_dims = latent_size, step_channels = step_conv_channels)\n",
    "    generator.apply(weights_init)\n",
    "    generator = generator.to(rank)\n",
    "    generator = torch.nn.SyncBatchNorm.convert_sync_batchnorm(generator)\n",
    "    generator = DDP(generator, device_ids=[rank], output_device=rank, find_unused_parameters=False)\n",
    "    \n",
    "    discriminator = Discriminator(step_channels = step_conv_channels)\n",
    "    discriminator.apply(weights_init)\n",
    "    discriminator = discriminator.to(rank)\n",
    "    discriminator = DDP(discriminator, device_ids=[rank], output_device=rank, find_unused_parameters=False)\n",
    "    if rank==0:\n",
    "        print('weights init done')\n",
    "    model = {\n",
    "        'generator' : generator,\n",
    "        'discriminator' : discriminator\n",
    "    }\n",
    "    criterion={\n",
    "        'generator' : generator_loss,\n",
    "        'discriminator' : discriminator_loss\n",
    "    }\n",
    "    if rank==0:\n",
    "        print('Model prepared, starting learning')\n",
    "    \n",
    "    epochs = 50\n",
    "    \n",
    "    logs = fit(rank, model, dataloader, criterion, epochs, lr, epochs_start = EPOCH_START)\n",
    "    \n",
    "    if rank==0:\n",
    "        print('Learning done, epochs: %d' %epochs)\n",
    "        \n",
    "    cleanup()\n",
    "    \n",
    "    #if rank==0:\n",
    "        #save_logs(logs)\n",
    "        #show_samples(model, amount=16)\n",
    "    \n",
    "world_size = 2\n",
    "if __name__ == '__main__':\n",
    "    mp.spawn(main, args=(world_size,), nprocs=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34963e6f",
   "metadata": {
    "papermill": {
     "duration": 21792.132802,
     "end_time": "2024-03-04T16:20:58.708355",
     "exception": false,
     "start_time": "2024-03-04T10:17:46.575553",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup done, starting preparing dataloader\n",
      "Dataloader prepared\n",
      "weights init done\n",
      "Model prepared, starting learning\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]Epoch [1/50], loss_g: 0.1249, loss_d: 1.9304, real_score: 0.0027, fake_score: -0.0938\n",
      "  2%|▋                                    | 1/50 [1:22:58<67:46:07, 4978.93s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 1\n",
      "  2%|▋                                    | 1/50 [1:22:59<67:46:18, 4979.16s/it]Epoch [2/50], loss_g: 0.1954, loss_d: 1.9770, real_score: -0.1450, fake_score: -0.1744\n",
      "Logs saved\n",
      "Saving samples\n",
      "  4%|█▍                                   | 2/50 [2:45:33<66:11:43, 4964.66s/it]Saving samples complete\n",
      "Model Saved! Epoch: 2\n",
      "  4%|█▍                                   | 2/50 [2:45:33<66:11:48, 4964.75s/it]Epoch [3/50], loss_g: 0.0717, loss_d: 1.9861, real_score: -0.0361, fake_score: -0.0539\n",
      "  6%|██▏                                  | 3/50 [4:07:24<64:29:48, 4940.19s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 3\n",
      "  8%|██▉                                  | 4/50 [5:29:30<63:02:59, 4934.35s/it]Epoch [4/50], loss_g: 0.0032, loss_d: 1.9874, real_score: 0.0329, fake_score: 0.0164\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 4\n",
      " 10%|███▋                                 | 5/50 [6:51:24<61:35:26, 4927.26s/it]Epoch [5/50], loss_g: 0.0145, loss_d: 1.9833, real_score: 0.0295, fake_score: 0.0079\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 5\n",
      " 10%|███▋                                 | 5/50 [6:51:25<61:35:27, 4927.29s/it]Epoch [6/50], loss_g: -0.0388, loss_d: 1.9816, real_score: 0.0901, fake_score: 0.0608\n",
      " 12%|████▍                                | 6/50 [8:13:17<60:09:47, 4922.44s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 6\n",
      " 14%|█████▏                               | 7/50 [9:35:08<58:45:02, 4918.65s/it]Epoch [7/50], loss_g: -0.0538, loss_d: 1.9621, real_score: 0.1230, fake_score: 0.0782\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 7\n",
      " 16%|█████▊                              | 8/50 [10:57:48<57:32:16, 4931.82s/it]Epoch [8/50], loss_g: -0.1010, loss_d: 1.9715, real_score: 0.1660, fake_score: 0.1311\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 8\n",
      " 18%|██████▍                             | 9/50 [12:21:45<56:32:27, 4964.58s/it]Epoch [9/50], loss_g: 0.0231, loss_d: 1.9433, real_score: 0.0770, fake_score: 0.0095\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 9\n",
      " 18%|██████▍                             | 9/50 [12:21:45<56:32:27, 4964.58s/it]Epoch [10/50], loss_g: 0.0667, loss_d: 1.9298, real_score: 0.0559, fake_score: -0.0261\n",
      " 20%|███████                            | 10/50 [13:45:44<55:24:58, 4987.47s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 10\n",
      " 22%|███████▋                           | 11/50 [15:12:17<54:42:50, 5050.53s/it]Epoch [11/50], loss_g: 0.0853, loss_d: 1.9227, real_score: 0.0418, fake_score: -0.0487\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 11\n",
      " 22%|███████▋                           | 11/50 [15:12:17<54:42:50, 5050.54s/it]Epoch [12/50], loss_g: 0.0837, loss_d: 1.9245, real_score: 0.0460, fake_score: -0.0423\n",
      " 24%|████████▍                          | 12/50 [16:34:56<53:01:06, 5022.81s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 12\n",
      " 26%|█████████                          | 13/50 [17:56:14<51:10:18, 4978.88s/it]Epoch [13/50], loss_g: 0.0932, loss_d: 1.9255, real_score: 0.0326, fake_score: -0.0541\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 13\n",
      " 26%|█████████                          | 13/50 [17:56:15<51:10:18, 4978.88s/it]Epoch [14/50], loss_g: 0.1153, loss_d: 1.9020, real_score: 0.0471, fake_score: -0.0661\n",
      " 28%|█████████▊                         | 14/50 [19:17:03<49:23:41, 4939.49s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 14\n",
      " 28%|█████████▊                         | 14/50 [19:17:03<49:23:41, 4939.49s/it]Epoch [15/50], loss_g: 0.1746, loss_d: 1.8503, real_score: 0.0662, fake_score: -0.1138\n",
      " 30%|██████████▌                        | 15/50 [20:37:59<47:46:44, 4914.41s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 15\n",
      " 30%|██████████▌                        | 15/50 [20:37:59<47:46:44, 4914.40s/it]Epoch [16/50], loss_g: 0.2665, loss_d: 1.8216, real_score: 0.0234, fake_score: -0.2085\n",
      "Logs saved\n",
      "Saving samples\n",
      " 32%|███████████▏                       | 16/50 [21:58:45<46:13:13, 4893.92s/it]Saving samples complete\n",
      "Model Saved! Epoch: 16\n",
      " 34%|███████████▉                       | 17/50 [23:20:13<44:50:38, 4892.07s/it]Epoch [17/50], loss_g: 0.2041, loss_d: 1.8122, real_score: 0.0851, fake_score: -0.1352\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 17\n",
      " 34%|███████████▉                       | 17/50 [23:20:13<44:50:38, 4892.07s/it]Epoch [18/50], loss_g: 0.2349, loss_d: 1.7877, real_score: 0.0980, fake_score: -0.1577\n",
      " 36%|████████████▌                      | 18/50 [24:42:14<43:33:45, 4900.81s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 18\n",
      " 38%|█████████████▎                     | 19/50 [26:03:56<42:12:10, 4900.99s/it]Epoch [19/50], loss_g: 0.1926, loss_d: 1.7932, real_score: 0.1167, fake_score: -0.1278\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 19\n",
      " 38%|█████████████▎                     | 19/50 [26:03:56<42:12:11, 4901.00s/it]Epoch [20/50], loss_g: 0.2030, loss_d: 1.7801, real_score: 0.1250, fake_score: -0.1359\n",
      " 40%|██████████████                     | 20/50 [27:25:09<40:46:24, 4892.82s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 20\n",
      " 40%|██████████████                     | 20/50 [27:25:10<40:46:24, 4892.82s/it]Epoch [21/50], loss_g: 0.2283, loss_d: 1.7447, real_score: 0.1493, fake_score: -0.1562\n",
      " 42%|██████████████▋                    | 21/50 [28:46:17<39:21:15, 4885.36s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 21\n",
      " 42%|██████████████▋                    | 21/50 [28:46:18<39:21:15, 4885.35s/it]Epoch [22/50], loss_g: 0.2749, loss_d: 1.6936, real_score: 0.1811, fake_score: -0.1931\n",
      " 44%|███████████████▍                   | 22/50 [30:07:35<37:58:44, 4883.01s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 22\n",
      " 44%|███████████████▍                   | 22/50 [30:07:35<37:58:44, 4883.01s/it]Epoch [23/50], loss_g: 0.3314, loss_d: 1.6284, real_score: 0.2211, fake_score: -0.2443\n",
      " 46%|████████████████                   | 23/50 [31:28:48<36:35:56, 4879.88s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 23\n",
      " 46%|████████████████                   | 23/50 [31:28:48<36:35:56, 4879.88s/it]Epoch [24/50], loss_g: 0.3433, loss_d: 1.5942, real_score: 0.2571, fake_score: -0.2590\n",
      " 48%|████████████████▊                  | 24/50 [32:50:22<35:16:26, 4884.11s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 24\n",
      " 48%|████████████████▊                  | 24/50 [32:50:22<35:16:27, 4884.12s/it]Epoch [25/50], loss_g: 0.3881, loss_d: 1.5437, real_score: 0.2892, fake_score: -0.3050\n",
      " 50%|█████████████████▌                 | 25/50 [34:11:30<33:53:04, 4879.39s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 25\n",
      " 52%|██████████████████▏                | 26/50 [35:32:57<32:32:42, 4881.75s/it]Epoch [26/50], loss_g: 0.4166, loss_d: 1.5189, real_score: 0.3083, fake_score: -0.3206\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 26\n",
      " 52%|██████████████████▏                | 26/50 [35:32:57<32:32:42, 4881.75s/it]Epoch [27/50], loss_g: 0.4621, loss_d: 1.4515, real_score: 0.3615, fake_score: -0.3647\n",
      " 54%|██████████████████▉                | 27/50 [36:54:10<31:10:16, 4878.98s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 27\n",
      " 54%|██████████████████▉                | 27/50 [36:54:10<31:10:16, 4878.98s/it]Epoch [28/50], loss_g: 0.4740, loss_d: 1.4381, real_score: 0.3693, fake_score: -0.3838\n",
      " 56%|███████████████████▌               | 28/50 [38:15:08<29:46:37, 4872.63s/it]Logs saved\n",
      "Saving samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving samples complete\n",
      "Model Saved! Epoch: 28\n",
      " 56%|███████████████████▌               | 28/50 [38:15:08<29:46:38, 4872.64s/it]Epoch [29/50], loss_g: 0.4868, loss_d: 1.4186, real_score: 0.3968, fake_score: -0.3908\n",
      " 58%|████████████████████▎              | 29/50 [39:36:02<28:23:32, 4867.24s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 29\n",
      " 58%|████████████████████▎              | 29/50 [39:36:02<28:23:31, 4867.24s/it]Epoch [30/50], loss_g: 0.5403, loss_d: 1.3624, real_score: 0.4398, fake_score: -0.4376\n",
      " 60%|█████████████████████              | 30/50 [40:57:37<27:05:08, 4875.41s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 30\n",
      " 60%|█████████████████████              | 30/50 [40:57:37<27:05:08, 4875.41s/it]Epoch [31/50], loss_g: 0.5335, loss_d: 1.3710, real_score: 0.4410, fake_score: -0.4307\n",
      " 62%|█████████████████████▋             | 31/50 [42:18:27<25:41:29, 4867.89s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 31\n",
      " 62%|█████████████████████▋             | 31/50 [42:18:27<25:41:29, 4867.89s/it]Epoch [32/50], loss_g: 0.5502, loss_d: 1.3511, real_score: 0.4554, fake_score: -0.4516\n",
      " 64%|██████████████████████▍            | 32/50 [43:39:39<24:20:45, 4869.21s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 32\n",
      " 64%|██████████████████████▍            | 32/50 [43:39:39<24:20:45, 4869.20s/it]Epoch [33/50], loss_g: 0.5773, loss_d: 1.3253, real_score: 0.4788, fake_score: -0.4742\n",
      "Logs saved\n",
      " 66%|███████████████████████            | 33/50 [45:01:32<23:03:17, 4882.23s/it]Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 33\n",
      " 66%|███████████████████████            | 33/50 [45:01:32<23:03:17, 4882.23s/it]Epoch [34/50], loss_g: 0.5809, loss_d: 1.3081, real_score: 0.4958, fake_score: -0.4830\n",
      " 68%|███████████████████████▊           | 34/50 [46:23:18<21:43:48, 4889.31s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 34\n",
      " 68%|███████████████████████▊           | 34/50 [46:23:18<21:43:48, 4889.31s/it]Epoch [35/50], loss_g: 0.5993, loss_d: 1.2742, real_score: 0.5327, fake_score: -0.5036\n",
      " 70%|████████████████████████▌          | 35/50 [47:45:06<20:23:46, 4895.09s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 35\n",
      " 72%|█████████████████████████▏         | 36/50 [49:06:38<19:01:58, 4894.18s/it]Epoch [36/50], loss_g: 0.7028, loss_d: 1.1564, real_score: 0.6453, fake_score: -0.5908\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 36\n",
      " 72%|█████████████████████████▏         | 36/50 [49:06:39<19:01:58, 4894.18s/it]Epoch [37/50], loss_g: 0.8458, loss_d: 1.0113, real_score: 0.8228, fake_score: -0.7193\n",
      " 74%|█████████████████████████▉         | 37/50 [50:29:01<17:43:33, 4908.76s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 37\n",
      " 74%|█████████████████████████▉         | 37/50 [50:29:01<17:43:33, 4908.76s/it]Epoch [38/50], loss_g: 0.8048, loss_d: 1.0466, real_score: 0.7792, fake_score: -0.6854\n",
      " 76%|██████████████████████████▌        | 38/50 [51:54:32<16:35:04, 4975.40s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 38\n",
      " 76%|██████████████████████████▌        | 38/50 [51:54:32<16:35:04, 4975.40s/it]Epoch [39/50], loss_g: 0.7263, loss_d: 1.1314, real_score: 0.6781, fake_score: -0.6203\n",
      " 78%|███████████████████████████▎       | 39/50 [53:19:51<15:20:02, 5018.39s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 39\n",
      " 78%|███████████████████████████▎       | 39/50 [53:19:51<15:20:02, 5018.40s/it]Epoch [40/50], loss_g: 0.6616, loss_d: 1.2042, real_score: 0.6014, fake_score: -0.5589\n",
      " 80%|████████████████████████████       | 40/50 [54:45:02<14:01:02, 5046.20s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 40\n",
      " 82%|████████████████████████████▋      | 41/50 [56:10:31<12:40:41, 5071.24s/it]Epoch [41/50], loss_g: 0.6848, loss_d: 1.1857, real_score: 0.6226, fake_score: -0.5723\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 41\n",
      " 84%|█████████████████████████████▍     | 42/50 [57:35:46<11:17:54, 5084.34s/it]Epoch [42/50], loss_g: 0.6871, loss_d: 1.1653, real_score: 0.6397, fake_score: -0.5861\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 42\n",
      " 86%|██████████████████████████████▉     | 43/50 [59:01:30<9:55:13, 5101.98s/it]Epoch [43/50], loss_g: 0.6938, loss_d: 1.1696, real_score: 0.6376, fake_score: -0.5842\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 43\n",
      " 86%|██████████████████████████████▉     | 43/50 [59:01:30<9:55:13, 5101.98s/it]Epoch [44/50], loss_g: 0.7087, loss_d: 1.1508, real_score: 0.6570, fake_score: -0.6017\n",
      " 88%|███████████████████████████████▋    | 44/50 [60:27:08<8:31:18, 5113.04s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 44\n",
      " 88%|███████████████████████████████▋    | 44/50 [60:27:09<8:31:18, 5113.04s/it]Epoch [45/50], loss_g: 0.6989, loss_d: 1.1633, real_score: 0.6472, fake_score: -0.5904\n",
      " 90%|████████████████████████████████▍   | 45/50 [61:52:54<7:06:54, 5122.83s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 45\n",
      " 90%|████████████████████████████████▍   | 45/50 [61:52:54<7:06:54, 5122.82s/it]Epoch [46/50], loss_g: 0.7013, loss_d: 1.1589, real_score: 0.6431, fake_score: -0.5952\n",
      " 92%|█████████████████████████████████   | 46/50 [63:18:30<5:41:47, 5126.88s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 46\n",
      " 94%|█████████████████████████████████▊  | 47/50 [64:43:36<4:16:01, 5120.56s/it]Epoch [47/50], loss_g: 0.7169, loss_d: 1.1403, real_score: 0.6664, fake_score: -0.6077\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 47\n",
      " 96%|██████████████████████████████████▌ | 48/50 [66:09:14<2:50:51, 5125.86s/it]Epoch [48/50], loss_g: 0.7294, loss_d: 1.1118, real_score: 0.6974, fake_score: -0.6295\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 48\n",
      " 96%|██████████████████████████████████▌ | 48/50 [66:09:15<2:50:51, 5125.86s/it]Epoch [49/50], loss_g: 0.7284, loss_d: 1.1115, real_score: 0.7004, fake_score: -0.6315\n",
      " 98%|███████████████████████████████████▎| 49/50 [67:35:12<1:25:35, 5135.44s/it]Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 49\n",
      "100%|██████████████████████████████████████| 50/50 [69:01:15<00:00, 4969.50s/it]\n",
      "Epoch [50/50], loss_g: 0.7610, loss_d: 1.0789, real_score: 0.7385, fake_score: -0.6526\n",
      "Logs saved\n",
      "Saving samples\n",
      "Saving samples complete\n",
      "Model Saved! Epoch: 50\n",
      "100%|██████████████████████████████████████| 50/50 [69:01:15<00:00, 4969.51s/it]\n",
      "Learning done, epochs: 50\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,2 python ddp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67814e0",
   "metadata": {
    "papermill": {
     "duration": 0.761064,
     "end_time": "2024-03-04T16:21:00.227486",
     "exception": false,
     "start_time": "2024-03-04T16:20:59.466422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4435831,
     "sourceId": 7616548,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 164833042,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21797.708696,
   "end_time": "2024-03-04T16:21:01.363852",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-04T10:17:43.655156",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
